{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Start by taking a walk for 30 minutes at a moderate pace. This should be done at least 3-4 times per week. \n",
      "\n",
      "2. After building a base, add some jogging to the routine. Start with an interval of jogging for 1 minute followed by 2 minutes of walking and repeat for 15 minutes. Do this 2-3 times per week.\n",
      "\n",
      "3. Once comfortable with the jogging, add running intervals. Start with an interval of running for 2 minutes followed by 2 minutes of walking and repeat for 15 minutes. Do this 2-3 times per week.\n",
      "\n",
      "4. As the body becomes accustomed to the running intervals, add longer running intervals. Start with an interval of running for 5 minutes followed by 2 minutes of walking and repeat for 20 minutes. Do this 2-3 times per week.\n",
      "\n",
      "5. Supplement the running routine with some strength training. This will help build muscle endurance and increase the overall health and strength of the body. Aim to do strength training 2-3 times per week.\n",
      "\n",
      "6. Finally, add some outdoor activities to the routine such as biking, hiking, swimming, or other activities that you enjoy. Aim to do at least one outdoor activity per week. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "print(llm(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EcoPure Hydration.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"eco-friendly water bottles\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "conversation.predict(input=\"Tell me about yourself.\")\n",
    "\n",
    "# Continue the conversation\n",
    "conversation.predict(input=\"What can you do?\")\n",
    "conversation.predict(input=\"How can you help me with data analysis?\")\n",
    "\n",
    "# Display the conversation\n",
    "print(conversation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Before executing the following code, make sure to have your\n",
    "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
    "\n",
    "# instantiate the LLM and embeddings models\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create our documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LockedException",
     "evalue": "This dataset cannot be open for writing as it is locked by another machine. Try loading the dataset with `read_only=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLockedException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m my_activeloop_dataset_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlangchain_course_from_zero_to_hero\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhub://\u001b[39m\u001b[39m{\u001b[39;00mmy_activeloop_org_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmy_activeloop_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m db \u001b[39m=\u001b[39m DeepLake(dataset_path\u001b[39m=\u001b[39mdataset_path, embedding_function\u001b[39m=\u001b[39membeddings)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/langchain/vectorstores/deeplake.py:136\u001b[0m, in \u001b[0;36mDeepLake.__init__\u001b[0;34m(self, dataset_path, token, embedding_function, read_only, ingestion_batch_size, num_workers, verbose, exec_option, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeeplake version should be >= 3.6.3, but you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mve installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mdeeplake\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m. Consider upgrading deeplake version \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m            pip install --upgrade deeplake.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path \u001b[39m=\u001b[39m dataset_path\n\u001b[0;32m--> 136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore \u001b[39m=\u001b[39m DeepLakeVectorStore(\n\u001b[1;32m    137\u001b[0m     path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path,\n\u001b[1;32m    138\u001b[0m     embedding_function\u001b[39m=\u001b[39membedding_function,\n\u001b[1;32m    139\u001b[0m     read_only\u001b[39m=\u001b[39mread_only,\n\u001b[1;32m    140\u001b[0m     token\u001b[39m=\u001b[39mtoken,\n\u001b[1;32m    141\u001b[0m     exec_option\u001b[39m=\u001b[39mexec_option,\n\u001b[1;32m    142\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    143\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id_tensor_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39mtensors() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/core/vectorstore/deeplake_vectorstore.py:119\u001b[0m, in \u001b[0;36mVectorStore.__init__\u001b[0;34m(self, path, tensor_params, embedding_function, read_only, ingestion_batch_size, num_workers, exec_option, token, overwrite, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m=\u001b[39m num_workers\n\u001b[1;32m    118\u001b[0m creds \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcreds\u001b[39m\u001b[39m\"\u001b[39m: kwargs[\u001b[39m\"\u001b[39m\u001b[39mcreds\u001b[39m\u001b[39m\"\u001b[39m]} \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcreds\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39mcreate_or_load_dataset(\n\u001b[1;32m    120\u001b[0m     tensor_params,\n\u001b[1;32m    121\u001b[0m     path,\n\u001b[1;32m    122\u001b[0m     token,\n\u001b[1;32m    123\u001b[0m     creds,\n\u001b[1;32m    124\u001b[0m     logger,\n\u001b[1;32m    125\u001b[0m     read_only,\n\u001b[1;32m    126\u001b[0m     exec_option,\n\u001b[1;32m    127\u001b[0m     embedding_function,\n\u001b[1;32m    128\u001b[0m     overwrite,\n\u001b[1;32m    129\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexec_option \u001b[39m=\u001b[39m exec_option\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/core/vectorstore/vector_search/dataset/dataset.py:49\u001b[0m, in \u001b[0;36mcreate_or_load_dataset\u001b[0;34m(tensor_params, dataset_path, token, creds, logger, read_only, exec_option, embedding_function, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m tensor_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m tensor_params \u001b[39m!=\u001b[39m DEFAULT_VECTORSTORE_TENSORS:\n\u001b[1;32m     45\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mVector Store is not empty. You shouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt specify tensor_params if you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre loading from existing dataset.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         )\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m load_dataset(\n\u001b[1;32m     50\u001b[0m         dataset_path,\n\u001b[1;32m     51\u001b[0m         token,\n\u001b[1;32m     52\u001b[0m         creds,\n\u001b[1;32m     53\u001b[0m         logger,\n\u001b[1;32m     54\u001b[0m         read_only,\n\u001b[1;32m     55\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m create_dataset(\n\u001b[1;32m     59\u001b[0m     logger,\n\u001b[1;32m     60\u001b[0m     tensor_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     67\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/core/vectorstore/vector_search/dataset/dataset.py:92\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dataset_path, token, creds, logger, read_only, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m dataset_path \u001b[39m==\u001b[39m DEFAULT_VECTORSTORE_DEEPLAKE_PATH:\n\u001b[1;32m     86\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m     87\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe default deeplake path location is used: \u001b[39m\u001b[39m{\u001b[39;00mDEFAULT_VECTORSTORE_DEEPLAKE_PATH\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m and it is not free. All addtionally added data will be added on\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m top of already existing deeplake dataset.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m dataset \u001b[39m=\u001b[39m deeplake\u001b[39m.\u001b[39mload(\n\u001b[1;32m     93\u001b[0m     dataset_path,\n\u001b[1;32m     94\u001b[0m     token\u001b[39m=\u001b[39mtoken,\n\u001b[1;32m     95\u001b[0m     read_only\u001b[39m=\u001b[39mread_only,\n\u001b[1;32m     96\u001b[0m     creds\u001b[39m=\u001b[39mcreds,\n\u001b[1;32m     97\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m check_tensors(dataset)\n\u001b[1;32m    103\u001b[0m logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    104\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDeep Lake Dataset in \u001b[39m\u001b[39m{\u001b[39;00mdataset_path\u001b[39m}\u001b[39;00m\u001b[39m already exists, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading from the storage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/util/spinner.py:140\u001b[0m, in \u001b[0;36mspinner.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/api/dataset.py:608\u001b[0m, in \u001b[0;36mdataset.load\u001b[0;34m(path, read_only, memory_cache_size, local_cache_size, creds, token, org_id, verbose, access_method, reset, check_integrity)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39m_load(\n\u001b[1;32m    605\u001b[0m         dataset_kwargs, access_method, check_integrity\u001b[39m=\u001b[39mcheck_integrity\n\u001b[1;32m    606\u001b[0m     )\n\u001b[1;32m    607\u001b[0m \u001b[39mexcept\u001b[39;00m (AgreementError, CheckoutError, LockedException) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 608\u001b[0m     \u001b[39mraise\u001b[39;00m e \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    610\u001b[0m     \u001b[39mif\u001b[39;00m access_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/api/dataset.py:604\u001b[0m, in \u001b[0;36mdataset.load\u001b[0;34m(path, read_only, memory_cache_size, local_cache_size, creds, token, org_id, verbose, access_method, reset, check_integrity)\u001b[0m\n\u001b[1;32m    590\u001b[0m     dataset_kwargs\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    591\u001b[0m         {\n\u001b[1;32m    592\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39maccess_method\u001b[39m\u001b[39m\"\u001b[39m: access_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    600\u001b[0m         }\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    603\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39m_load(\n\u001b[1;32m    605\u001b[0m         dataset_kwargs, access_method, check_integrity\u001b[39m=\u001b[39mcheck_integrity\n\u001b[1;32m    606\u001b[0m     )\n\u001b[1;32m    607\u001b[0m \u001b[39mexcept\u001b[39;00m (AgreementError, CheckoutError, LockedException) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    608\u001b[0m     \u001b[39mraise\u001b[39;00m e \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/api/dataset.py:675\u001b[0m, in \u001b[0;36mdataset._load\u001b[0;34m(dataset_kwargs, access_method, create, check_integrity)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load\u001b[39m(dataset_kwargs, access_method\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, create\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, check_integrity\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    674\u001b[0m     \u001b[39mif\u001b[39;00m access_method \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 675\u001b[0m         ret \u001b[39m=\u001b[39m dataset_factory(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs)\n\u001b[1;32m    676\u001b[0m         \u001b[39mif\u001b[39;00m create:\n\u001b[1;32m    677\u001b[0m             dataset_created(ret)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/core/dataset/__init__.py:23\u001b[0m, in \u001b[0;36mdataset_factory\u001b[0;34m(path, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     clz \u001b[39m=\u001b[39m Dataset\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m clz \u001b[39min\u001b[39;00m {Dataset, DeepLakeCloudDataset}:\n\u001b[0;32m---> 23\u001b[0m     ds \u001b[39m=\u001b[39m clz(path\u001b[39m=\u001b[39mpath, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     24\u001b[0m     \u001b[39mif\u001b[39;00m ds\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvirtual-datasource\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     25\u001b[0m         ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39m_get_view()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain2023/lib/python3.11/site-packages/deeplake/core/dataset/dataset.py:246\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, storage, index, group_index, read_only, public, token, org_id, verbose, version_state, path, address, is_iteration, link_creds, pad_tensors, lock, enabled_tensors, view_base, libdeeplake_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_derived_attributes(address\u001b[39m=\u001b[39maddress)\n\u001b[1;32m    245\u001b[0m \u001b[39mexcept\u001b[39;00m LockedException:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mraise\u001b[39;00m LockedException(\n\u001b[1;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis dataset cannot be open for writing as it is locked by another machine. Try loading the dataset with `read_only=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    249\u001b[0m \u001b[39mexcept\u001b[39;00m ReadOnlyModeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    250\u001b[0m     \u001b[39mraise\u001b[39;00m ReadOnlyModeError(\n\u001b[1;32m    251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis dataset cannot be open for writing as you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have permissions. Try loading the dataset with `read_only=True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m     )\n",
      "\u001b[0;31mLockedException\u001b[0m: This dataset cannot be open for writing as it is locked by another machine. Try loading the dataset with `read_only=True`."
     ]
    }
   ],
   "source": [
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"maitemarzoratti\" \n",
    "my_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# add documents to our Deep Lake dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m db\u001b[39m.\u001b[39madd_documents(docs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm,\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Napoleone was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Napoleone born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Napoleon Bonaparte was born on 15 August 1769.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://maitemarzoratti/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://maitemarzoratti/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (4, 1536)  float32   None   \n",
      "    id        text      (4, 1)      str     None   \n",
      " metadata     json      (4, 1)      str     None   \n",
      "   text       text      (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9174e608-1399-11ee-91aa-d0a637ea8e5b',\n",
       " '9174e702-1399-11ee-91aa-d0a637ea8e5b']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the existing Deep Lake dataset and specify the embedding function\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# create new documents\n",
    "texts = [\n",
    "    \"Lady Gaga was born in 28 March 1986\",\n",
    "    \"Michael Jeffrey Jordan was born in 17 February 1963\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://maitemarzoratti/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# instantiate the wrapper class for GPT3\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# create a retriever from the db\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "\tllm=llm, chain_type=\"stuff\", retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# instantiate a tool that uses the retriever\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# create an agent that uses the tool\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Michael Jordan was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Michael Jordan born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Michael Jordan was born on 17 February 1963.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Michael Jordan born?\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to set the environment variables\n",
    "# “GOOGLE_API_KEY” and “GOOGLE_CSE_ID” to be able to use\n",
    "# Google Search via API.\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"google-search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True,\n",
    "                         max_iterations=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"STATE OF HAWAII. 1 Child's First Name. (Type or print). BARACK. CERTIFICATE OF LIVE BIRTH lb. Middle Name. HUSSE. HUSSEIN. FILE. NUMBER 151. Barack Hussein Obama II is an American politician who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party,\\xa0... His full name is Barack Hussein Obama II. Since the “II” is simply because he was named for his father, his last name is Obama. Jan 19, 2017 ... Jordan Barack Treasure, New York City, born in 2008 ... Jordan Barack Treasure made national news when he was the focus of a New York newspaper\\xa0... Portrait of George Washington, the 1st President of the United States ... Portrait of Barack Obama, the 44th President of the United States\\xa0... Feb 9, 2015 ... Michael Jordan misspelled Barack Obama's first name on 50th-birthday gift ... and he said, 'I can't put this up, he misspelled my name! First Lady Michelle LaVaughn Robinson Obama is a lawyer, writer, and the wife of the 44th President, Barack Obama. She is the first African-American First\\xa0... Jul 22, 2017 ... Nevertheless, he was proud enough of his formal name that after he and Ann Dunham married in 1961, they named their son, Barack Hussein Obama II\\xa0... Aug 18, 2017 ... It took him several seconds and multiple clues to remember former President Barack Obama's first name. Miller knew that every answer had to\\xa0... Barack Hussein Obama II was born August 4, 1961, in Honolulu, Hawaii, to parents Barack H. Obama, Sr., and Stanley Ann Dunham. His parents divorced when he was\\xa0...\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about the Mars rover\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. NASA's Curiosity rover is discovering odd rocks halfway into a region called the \"clay-bearing unit.\" ... This panorama of a location called \"Teal Ridge\" was ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... Get the latest news releases about the Perseverance rover mission. Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ... Apr 28, 2023 ... Friday's news comes days after mission leaders acknowledged that the Zhurong rover has yet to wake up since going into hibernation for the ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for National Breaking News Alerts. Sep 16, 2022 ... Since July, NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars. Nasa Mars lander study reveals 'main source of heat' on Red Planet · NASA/ESA/A. Simon (Goddard Space Flight Center) and M.H. Wong.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest news about the Mars rover is that the mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. China's Mars rover has likely suffered excessive damage due to hibernation, and NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover is that the mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. China's Mars rover has likely suffered excessive damage due to hibernation, and NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest news about the Mars rover?\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Write a summary of the following text: {query}\"\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to set the environment variables\n",
    "# “GOOGLE_API_KEY” and “GOOGLE_CSE_ID” to be able to use\n",
    "# Google Search via API.\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for finding information about recent events\"\n",
    "    ),\n",
    "    Tool(\n",
    "       name='Summarizer',\n",
    "       func=summarize_chain.run,\n",
    "       description='useful for summarizing texts'\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the latest news and then summarize it.\n",
      "Action: Search\n",
      "Action Input: Latest news on the elections in Argentina\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mOct 28, 2019 ... Centre-left opposition candidate Alberto Fernández has been elected president of Argentina in a vote dominated by economic concerns. May 14, 2023 ... Argentina's ruling Peronist party wins provincial elections ... May 14 - Argentina's ruling Peronist party posted strong wins in elections Sunday, ... May 5, 2023 ... Polls have him capturing as much as a quarter of potential votes. The current leftist president says he won't run for reelection, and the right ... Jun 1, 2023 ... A new Executive Council was also elected. “In these times when inequality and climate change are the greatest global threats, the WMO must ... Apr 21, 2023 ... Argentine President Alberto Fernandez will not run in the country's ... German Chancellor Olaf Scholz (not pictured) hold a news conference, ... May 4, 2023 ... In October Argentines will go to the polls to elect a new government. For months the leading candidate to oppose the current Peronist ... Google has different requirements for political and election advertising based on ... to run New Zealand Election Ads in any region outside New Zealand. The coup came on March 24, 1976 when an Argentine military junta removed Peron from power. The U.S. gave limited support to the new government, through the ... Dec 12, 2022 ... The February election will be held under the new Electoral Act, which seeks to make the vote more transparent and secure. Jan 19, 2023 ... Inflation is top of mind for voters in Argentina's 2023 election season. ... in Congress (one supposedly led to the passage of a new tax).\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to summarize the information I found.\n",
      "Action: Summarizer\n",
      "Action Input: Oct 28, 2019 ... Centre-left opposition candidate Alberto Fernández has been elected president of Argentina in a vote dominated by economic concerns. May 14, 2023 ... Argentina's ruling Peronist party wins provincial elections ... May 14 - Argentina's ruling Peronist party posted strong wins in elections Sunday, ... May 5, 2023 ... Polls have him capturing as much as a quarter of potential votes. The current leftist president says he won't run for reelection, and the right ... Jun 1, 2023 ... A new Executive Council was also elected. “In these times when inequality and climate change are the greatest global threats, the WMO must ... Apr 21, 2023 ... Argentine President Alberto Fernandez will not run in the country's ... German Chancellor Olaf Scholz (not pictured) hold a news conference, ... May 4, 2023 ... In October Argentines will go to the polls to elect a new government. For months the leading candidate to oppose the current Peronist ... Google has different requirements for political and election advertising based on ... to run New Zealand Election Ads in any region outside New Zealand. The coup came\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m after Alberto Fernández was elected president of Argentina in October 2019, with the Peronist party dominating provincial elections in May 2023. Polls showed Fernández capturing as much as a quarter of potential votes, and he announced he would not run for reelection. In April 2023, German Chancellor Olaf Scholz and Argentine President Alberto Fernandez held a news conference, and in May 2023, Argentines went to the polls to elect a new government. Google has different requirements for political and election advertising based on the region.\n",
      "\n",
      "In October 2019, Alberto Fernández of the centre-left opposition was elected president of Argentina, with the Peronist party dominating provincial elections in May 2023. Fernández was predicted to capture as much as a quarter of potential votes, and announced he would not run for reelection. In April 2023, German Chancellor Olaf Scholz and Argentine President Alberto Fernandez held a news conference, and in May 2023, Argentines went to the polls to elect a new government. Google has different requirements for political and election advertising based on the region.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: In October 2019, Alberto Fernández of the centre-left opposition was elected president of Argentina, with the Peronist party dominating provincial elections in May 2023. Fernández was predicted to capture as much as a quarter of potential votes, and announced he would not run for reelection. In April 2023, German Chancellor Olaf Scholz and Argentine President Alberto Fernandez held a news conference, and in May 2023, Argentines went to the polls to elect a new government. Google has different requirements for political and election advertising based on the region.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "In October 2019, Alberto Fernández of the centre-left opposition was elected president of Argentina, with the Peronist party dominating provincial elections in May 2023. Fernández was predicted to capture as much as a quarter of potential votes, and announced he would not run for reelection. In April 2023, German Chancellor Olaf Scholz and Argentine President Alberto Fernandez held a news conference, and in May 2023, Argentines went to the polls to elect a new government. Google has different requirements for political and election advertising based on the region.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What are the latest news on the elections in argentina? Then summarize the results.\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
